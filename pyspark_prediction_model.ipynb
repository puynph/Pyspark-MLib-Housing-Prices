{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f384e63f-72c8-4c44-854b-26c29004ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe14975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"version_check\").getOrCreate()\n",
    "\n",
    "# Print the PySpark version\n",
    "print(\"PySpark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5378beea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- housing_median_age: double (nullable = true)\n",
      " |-- total_rooms: double (nullable = true)\n",
      " |-- total_bedrooms: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- households: double (nullable = true)\n",
      " |-- median_income: double (nullable = true)\n",
      " |-- median_house_value: double (nullable = true)\n",
      " |-- ocean_proximity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").load(\"housing.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc618e",
   "metadata": {},
   "source": [
    "#### Rearrange the DataFrame columns according to the newly created 'id' column at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e4d52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  1|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df = df.withColumn('id', monotonically_increasing_id())\n",
    "\n",
    "df = df[['id'] + df.columns[:-1]]\n",
    "\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcfb01",
   "metadata": {},
   "source": [
    "#### Split the dataframe into training and testing sets with a ratio of 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9847c87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[id: bigint, longitude: double, latitude: double, housing_median_age: double, total_rooms: double, total_bedrooms: double, population: double, households: double, median_income: double, median_house_value: double, ocean_proximity: string],\n",
       " DataFrame[id: bigint, longitude: double, latitude: double, housing_median_age: double, total_rooms: double, total_bedrooms: double, population: double, households: double, median_income: double, median_house_value: double, ocean_proximity: string])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa065f87",
   "metadata": {},
   "source": [
    "#### Retrieve the numerical and categorical values seperately\n",
    "### Numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c8718c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features_lst = train.columns\n",
    "numerical_features_lst.remove('median_house_value')\n",
    "numerical_features_lst.remove('id')\n",
    "numerical_features_lst.remove('ocean_proximity')\n",
    "\n",
    "numerical_features_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e7c14",
   "metadata": {},
   "source": [
    "####  Impute missing values in the dataframe: filling in missing or null values in a dataset with some estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e62620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Create an Imputer instance\n",
    "imputer = Imputer(inputCols=numerical_features_lst,\n",
    "                  outputCols=numerical_features_lst)\n",
    "\n",
    "imputer = imputer.fit(train)\n",
    "\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734b74d",
   "metadata": {},
   "source": [
    "###  Create a single vector column from multiple numerical feature columns. \n",
    "##### Machine learning algorithms in PySpark expect the input features to be in vector format. By using VectorAssembler, I can create a single feature column that can be used as input to these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e235791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|    [-122.23,37.88,41...|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|    [-122.24,37.85,52...|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numerical_vector_assembler = VectorAssembler(inputCols=numerical_features_lst,\n",
    "                                             outputCol='numerical_feature_vector')\n",
    "\n",
    "train = numerical_vector_assembler.transform(train)\n",
    "test = numerical_vector_assembler.transform(test)\n",
    "\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccc093d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(numerical_feature_vector=DenseVector([-122.23, 37.88, 41.0, 880.0, 129.0, 322.0, 126.0, 8.3252])),\n",
       " Row(numerical_feature_vector=DenseVector([-122.24, 37.85, 52.0, 1467.0, 190.0, 496.0, 177.0, 7.2574]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('numerical_feature_vector').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94891459",
   "metadata": {},
   "source": [
    "#### Fit the scale on training set to memorize the std and mean. The standardization process involves subtracting the mean value of the feature and dividing by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe930e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|scaled_numerical_feature_vector|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|    [-122.23,37.88,41...|           [-1.3189315963185...|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|    [-122.24,37.85,52...|           [-1.3239057253870...|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol='numerical_feature_vector',\n",
    "                        outputCol='scaled_numerical_feature_vector',\n",
    "                        withStd=True, withMean=True)\n",
    "\n",
    "scaler = scaler.fit(train)\n",
    "\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665060a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaled_numerical_feature_vector=DenseVector([-1.3189, 1.0447, 0.9848, -0.8074, -0.9714, -0.9613, -0.9732, 2.3336])),\n",
       " Row(scaled_numerical_feature_vector=DenseVector([-1.3239, 1.0308, 1.8606, -0.537, -0.8268, -0.8103, -0.8407, 1.7751]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('scaled_numerical_feature_vector').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4d942",
   "metadata": {},
   "source": [
    "### Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5429f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|scaled_numerical_feature_vector|ocean_category_index|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|    [-122.23,37.88,41...|           [-1.3189315963185...|                 3.0|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|    [-122.24,37.85,52...|           [-1.3239057253870...|                 3.0|\n",
      "|  3|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|    [-122.25,37.85,52...|           [-1.3288798544555...|                 3.0|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol='ocean_proximity',\n",
    "                        outputCol='ocean_category_index')\n",
    "\n",
    "indexer = indexer.fit(train)\n",
    "train = indexer.transform(train)\n",
    "test = indexer.transform(test)\n",
    "\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c04eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Row(ocean_category_index=0.0),\n",
       " Row(ocean_category_index=1.0),\n",
       " Row(ocean_category_index=2.0),\n",
       " Row(ocean_category_index=3.0),\n",
       " Row(ocean_category_index=4.0)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.select('ocean_category_index').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45603a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|scaled_numerical_feature_vector|ocean_category_index|ocean_category_one_hot|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|    [-122.23,37.88,41...|           [-1.3189315963185...|                 3.0|         (4,[3],[1.0])|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|    [-122.24,37.85,52...|           [-1.3239057253870...|                 3.0|         (4,[3],[1.0])|\n",
      "|  3|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|    [-122.25,37.85,52...|           [-1.3288798544555...|                 3.0|         (4,[3],[1.0])|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(inputCol='ocean_category_index',\n",
    "                                outputCol='ocean_category_one_hot')\n",
    "\n",
    "one_hot_encoder = one_hot_encoder.fit(train)\n",
    "\n",
    "train = one_hot_encoder.transform(train)\n",
    "test = one_hot_encoder.transform(test)\n",
    "\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88385a5f",
   "metadata": {},
   "source": [
    "#### COMBINE FEATURES: Assemble numerical and categorical (one-hot encoded) features into a single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c208efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|scaled_numerical_feature_vector|ocean_category_index|ocean_category_one_hot|final_feature_vector|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|    [-122.23,37.88,41...|           [-1.3189315963185...|                 3.0|         (4,[3],[1.0])|[-1.3189315963185...|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|    [-122.24,37.85,52...|           [-1.3239057253870...|                 3.0|         (4,[3],[1.0])|[-1.3239057253870...|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=['scaled_numerical_feature_vector',\n",
    "                                       'ocean_category_one_hot'],\n",
    "                            outputCol='final_feature_vector')\n",
    "\n",
    "train = assembler.transform(train)\n",
    "test = assembler.transform(test)\n",
    "train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90c10d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(final_feature_vector=DenseVector([-1.3189, 1.0447, 0.9848, -0.8074, -0.9714, -0.9613, -0.9732, 2.3336, 0.0, 0.0, 0.0, 1.0])),\n",
       " Row(final_feature_vector=DenseVector([-1.3239, 1.0308, 1.8606, -0.537, -0.8268, -0.8103, -0.8407, 1.7751, 0.0, 0.0, 0.0, 1.0]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('final_feature_vector').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68dee51",
   "metadata": {},
   "source": [
    "#### Train a linear regression model on the training data and use that model to predict the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6337ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+----------------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|scaled_numerical_feature_vector|ocean_category_index|ocean_category_one_hot|final_feature_vector|predicted_median_house_value|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+----------------------------+\n",
      "|  0|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|    [-122.23,37.88,41...|           [-1.3189315963185...|                 3.0|         (4,[3],[1.0])|[-1.3189315963185...|           406892.1265315375|\n",
      "|  2|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|    [-122.24,37.85,52...|           [-1.3239057253870...|                 3.0|         (4,[3],[1.0])|[-1.3239057253870...|           377526.7282381223|\n",
      "|  3|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|    [-122.25,37.85,52...|           [-1.3288798544555...|                 3.0|         (4,[3],[1.0])|[-1.3288798544555...|          320875.22171548323|\n",
      "|  4|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|    [-122.25,37.85,52...|           [-1.3288798544555...|                 3.0|         (4,[3],[1.0])|[-1.3288798544555...|          256428.45632578066|\n",
      "|  5|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|       NEAR BAY|    [-122.25,37.85,52...|           [-1.3288798544555...|                 3.0|         (4,[3],[1.0])|[-1.3288798544555...|           263025.0979292289|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='final_feature_vector',\n",
    "                      labelCol='median_house_value')\n",
    "\n",
    "lr = lr.fit(train)\n",
    "pred_train_df = lr.transform(train).withColumnRenamed('prediction',\n",
    "                                                      'predicted_median_house_value')\n",
    "\n",
    "pred_train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a43db7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+----------------------------+\n",
      "| id|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|numerical_feature_vector|scaled_numerical_feature_vector|ocean_category_index|ocean_category_one_hot|final_feature_vector|predicted_median_house_value|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+----------------------------+\n",
      "|  1|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|    [-122.22,37.86,21...|           [-1.3139574672501...|                 3.0|         (4,[3],[1.0])|[-1.3139574672501...|           421919.1044080257|\n",
      "| 12|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|       NEAR BAY|    [-122.26,37.85,52...|           [-1.3338539835240...|                 3.0|         (4,[3],[1.0])|[-1.3338539835240...|          232342.53392105817|\n",
      "| 14|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|       NEAR BAY|    [-122.26,37.85,52...|           [-1.3338539835240...|                 3.0|         (4,[3],[1.0])|[-1.3338539835240...|          204610.13331481308|\n",
      "| 16|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|       NEAR BAY|    [-122.27,37.85,52...|           [-1.3388281125924...|                 3.0|         (4,[3],[1.0])|[-1.3388281125924...|          216047.83525932897|\n",
      "| 24|  -122.27|   37.84|              52.0|     2224.0|         437.0|    1006.0|     422.0|          2.6|          132600.0|       NEAR BAY|    [-122.27,37.84,52...|           [-1.3388281125924...|                 3.0|         (4,[3],[1.0])|[-1.3388281125924...|            213437.479426166|\n",
      "+---+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+------------------------+-------------------------------+--------------------+----------------------+--------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test_df = lr.transform(test).withColumnRenamed('prediction', 'predicted_median_house_value')\n",
    "\n",
    "pred_test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de6258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>numerical_feature_vector</th>\n",
       "      <th>scaled_numerical_feature_vector</th>\n",
       "      <th>ocean_category_index</th>\n",
       "      <th>ocean_category_one_hot</th>\n",
       "      <th>final_feature_vector</th>\n",
       "      <th>predicted_median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>[-122.22, 37.86, 21.0, 7099.0, 1106.0, 2401.0,...</td>\n",
       "      <td>[-1.3139574672501082, 1.0354255364586464, -0.6...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0)</td>\n",
       "      <td>[-1.3139574672501082, 1.0354255364586464, -0.6...</td>\n",
       "      <td>421919.104408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>3.0750</td>\n",
       "      <td>213500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>[-122.26, 37.85, 52.0, 2491.0, 474.0, 1098.0, ...</td>\n",
       "      <td>[-1.3338539835240164, 1.0307644190375265, 1.86...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0)</td>\n",
       "      <td>[-1.3338539835240164, 1.0307644190375265, 1.86...</td>\n",
       "      <td>232342.533921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0   1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "1  12    -122.26     37.85                52.0       2491.0           474.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \\\n",
       "0      2401.0      1138.0         8.3014            358500.0        NEAR BAY   \n",
       "1      1098.0       468.0         3.0750            213500.0        NEAR BAY   \n",
       "\n",
       "                            numerical_feature_vector  \\\n",
       "0  [-122.22, 37.86, 21.0, 7099.0, 1106.0, 2401.0,...   \n",
       "1  [-122.26, 37.85, 52.0, 2491.0, 474.0, 1098.0, ...   \n",
       "\n",
       "                     scaled_numerical_feature_vector  ocean_category_index  \\\n",
       "0  [-1.3139574672501082, 1.0354255364586464, -0.6...                   3.0   \n",
       "1  [-1.3338539835240164, 1.0307644190375265, 1.86...                   3.0   \n",
       "\n",
       "  ocean_category_one_hot                               final_feature_vector  \\\n",
       "0   (0.0, 0.0, 0.0, 1.0)  [-1.3139574672501082, 1.0354255364586464, -0.6...   \n",
       "1   (0.0, 0.0, 0.0, 1.0)  [-1.3338539835240164, 1.0307644190375265, 1.86...   \n",
       "\n",
       "   predicted_median_house_value  \n",
       "0                 421919.104408  \n",
       "1                 232342.533921  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_pd_df = pred_test_df.toPandas()\n",
    "\n",
    "pred_test_pd_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
